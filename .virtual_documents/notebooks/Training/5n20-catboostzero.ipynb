get_ipython().run_line_magic("load_ext", " autoreload")
get_ipython().run_line_magic("autoreload", " 2")

from pathlib import Path
from typing import List, Callable, Tuple, Any
from wandb.wandb_run import Run
from datetime import datetime, timedelta

from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from catboost import CatBoostClassifier, Pool, metrics, cv

import attr
import pandas as pd
import gc
import os
import wandb
import nest_asyncio
import logging
import sys
import numpy as np

nest_asyncio.apply()

while "freqtrade" not in os.listdir():
    os.chdir("..")
    if "freqtrade" in os.listdir():
        nest_asyncio.apply()
        logger = logging.getLogger("freqtrade.ml")
        handler = logging.StreamHandler(stream=sys.stdout)
        handler.setFormatter(logging.Formatter("%(name)s - %(message)s"))
        logger.addHandler(handler)
        logger.setLevel(logging.DEBUG)
    
from freqtrade.ml.lightning import LightningModule, LightningConfig
from freqtrade.ml.trainer import TradingTrainer
from freqtrade.ml.container import LightningContainer
from freqtrade.ml import loader, lightning_utils

from freqtrade.nbtools.helper import free_mem
from freqtrade.nbtools.pairs import PAIRS_HIGHCAP_NONSTABLE

container = None

if container is not None:
    print("Deleting container")
    free_mem(container)
    
gc.collect()


attr.s(repr=False)
class CatBoost(LightningModule):
    """ Template for LightningModule """
        
    def on_configure(self) -> LightningConfig:
        
        # This datetime can be replaced with datetime.now()
        now = datetime(2021, 8, 10)
        
        # Lighting Configuration
        config = LightningConfig(
            
            # Basic info
            name        = "5n20-catboostzero",
            timeframe   = "5m",
            exchange    = "binance",
            
            # Train and validation datetime
            trainval_start  = now - timedelta(days=62),
            trainval_end    = now - timedelta(days=31),
            
            # Backtest Optimization datetime
            opt_start = now - timedelta(days=30),
            opt_end   = now - timedelta(days=15),
            
            # Unbiased Backtest datetime
            test_start = now - timedelta(days=14),
            test_end   = now,
        )
        
        # Optional custom config attributes
        config.add_custom("num_epochs", 2000)
        config.add_custom("num_future_candles", 4)
        config.add_custom("num_classification_classes", 3)
        config.add_custom("hardware", "CPU")
        
        return config
        
    def on_get_data_paths(self, cwd: Path, timeframe: str, exchange: str) -> List[Path]:
        path_data_exchange = cwd.parent / "mount" / "data" / exchange

        return [
            datapath
            for datapath in list(path_data_exchange.glob(f"*-{timeframe}.json"))
            if datapath.name.split("-")[0].replace("_", "/")
            in PAIRS_HIGHCAP_NONSTABLE
        ]
    
    def on_add_features(self, df_onepair: pd.DataFrame) -> pd.DataFrame:
        import talib.abstract as ta
        import pandas_ta as pdta
        import freqtrade.vendor.qtpylib.indicators as qtpylib

        # Start add features (EVEN ONLY!)
        spaces = [4, 8, 14, 26, 50, 76, 100, 200]
        
        for i in spaces:
            i_half = int(i / 2)
            
            df_onepair[f"ml_is_above_ema{i}"] = df_onepair["close"] > ta.EMA(df_onepair["close"], timeperiod=i)
            
            df_onepair["macd"], df_onepair["macdsignal"], _ = ta.MACD(df_onepair["close"], 
                                                 fastperiod=i_half, 
                                                 slowperiod=i, 
                                                 signalperiod=9)
            df_onepair[f"ml_is_macd{i}_crossup"] = qtpylib.crossed_above(df_onepair["macd"], df_onepair["macdsignal"])
            df_onepair[f"ml_is_macd{i}_crossdown"] = qtpylib.crossed_below(df_onepair["macd"], df_onepair["macdsignal"])
            df_onepair = df_onepair.drop(columns=["macd", "macdsignal"])
            
            df_onepair[f"ml_is_rsi{i}_above50"] = ta.RSI(df_onepair["close"], timeperiod=i) > 50
            
            tema = ta.TEMA(df_onepair["close"], timeperiod=i)
            df_onepair[f"ml_is_tema{i}_crossup"] = qtpylib.crossed_above(df_onepair["close"], tema)
            df_onepair[f"ml_is_tema{i}_crossdown"] = qtpylib.crossed_below(df_onepair["close"], tema)
            
            df_onepair[f"ml_is_volume_above_ema{i}"] = df_onepair["volume"] > ta.EMA(df_onepair["volume"], timeperiod=i)

        return df_onepair
    
    def on_add_labels(self, df_onepair: pd.DataFrame) -> pd.DataFrame:
        # Create labels for classification task
        future_price = df_onepair['close'].shift(-self.config.num_future_candles)
        ml_label = (future_price - df_onepair['close']) / df_onepair['close']
        df_onepair[self.config.column_y] = pd.qcut(ml_label, self.config.num_classification_classes, labels=False)
        return df_onepair
    
    def on_final_processing(self, df_allpairs: pd.DataFrame) -> Tuple[Any, Any, Any, Any]:
        df_allpairs = self._balance_class_dataset(df_allpairs)
        X = df_allpairs[self.config.columns_x]
        y = df_allpairs[self.config.column_y]
        X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=1)
        return X_train, X_val, y_train, y_val
    
    def _balance_class_dataset(self, df_allpairs: pd.DataFrame) -> pd.DataFrame:
        """Balance num of datas in every class"""
        lengths_every_class = list(df_allpairs.groupby(by=["ml_label"]).count()["date"])
        df_allpairs_copy = pd.DataFrame()

        for classname in df_allpairs["ml_label"].unique():
            minimum_of_all = min(lengths_every_class)
            df_allpairs_copy = df_allpairs_copy.append(df_allpairs.loc[df_allpairs["ml_label"] == classname, :].iloc[:minimum_of_all])

        # Performance improvements
        df_allpairs_copy = df_allpairs_copy.astype(
            {col: "float32" for col in df_allpairs_copy.columns if "float" in str(df_allpairs_copy[col].dtype)}
        )
        free_mem(df_allpairs)
        return df_allpairs_copy
    
    def on_define_model(self, run: Run, X_train, X_val, y_train, y_val) -> Any:
        return CatBoostClassifier(
            iterations=self.config.num_epochs, 
            task_type=self.config.hardware,
         )
    
    def on_start_training(self, run: Run, X_train, X_val, y_train, y_val):
        print("Start Training...")
        self.model: CatBoostClassifier
        self.model.fit(
            X_train, y_train,
            eval_set=[(X_val, y_val)]
        )
        print("Accuracy: %.2f" % self.model.score(X_val, y_val))
    
    def on_predict(self, df_input_onepair: pd.DataFrame) -> pd.DataFrame:
        df_input_np = df_input_onepair.to_numpy()
        preds = self.model.predict_proba(df_input_np)
        df_preds = pd.DataFrame(preds)
        
        return df_preds
    
    def on_training_step(self, run: Run, data: dict):
        raise NotImplementedError()


module = CatBoost()


df_: pd.DataFrame = lightning_utils.get_dataset_df(module)
dates = df_["date"]
df_ = df_[module.config.columns_x + [module.config.column_y]]
df_


def dataframe_statistics(df_: pd.DataFrame):
    # Detect nan, infinity, and too large values in dataset
    print("N rows na:", str(df_.shape[0] - df_.dropna().shape[0]))
    print("N rows inf:", str(df_.shape[0] - df_.replace([np.inf, -np.inf], np.nan).dropna().shape[0]))
    print("Cols na:", str(df_.columns[df_.isna().any()].tolist()))
    print("Cols inf:", str(list(df_.columns.to_series()[np.isinf(df_).any()])))

    # Detect columns with irregular datatypes
    supported_datatypes = ["float32"]
    print("Irregular (col, dtypes):", str([(it, df_[it].dtype) for it in df_.columns if df_[it].dtype not in supported_datatypes]))

    # Dataset statistics
    print("Dataset Length: %s" % len(df_))
    print("Date Min: %s" % dates.min())
    print("Date Max: %s" % dates.max())
    print("Num feature columns: %i" % (len(df_.columns) - 1))
    
dataframe_statistics(df_)


# Dataset labels
print(df_["ml_label"])
df_["ml_label"].hist()


# Unload dataset after EDA to save memory
free_mem(df_)


with wandb.init(project=module.config.name) as run:
    trainer = TradingTrainer()
    container = trainer.fit(module, run, True)


# Validate prediction function by simulate inserting freqtrade data into predict function
df_with_preds = trainer.validate_predict(container)
df_with_preds


container.config



