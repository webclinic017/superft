{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69348244-3302-4662-afb6-afe8c3e47449",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from pathlib import Path\n",
    "from collections import deque\n",
    "from threading import Thread\n",
    "import os\n",
    "import logging\n",
    "import time\n",
    "import asyncio\n",
    "import random\n",
    "import wandb\n",
    "\n",
    "if \"freqtrade\" not in os.listdir():\n",
    "    import nest_asyncio\n",
    "    os.chdir(\"..\")\n",
    "    nest_asyncio.apply()\n",
    "    # Uncomment if you want to enable Freqtrade Logging\n",
    "#     logging.basicConfig(format='%(asctime)-15s - %(message)s')\n",
    "#     logging.root.setLevel(logging.WARNING)\n",
    "\n",
    "from freqtrade.commands.data_commands import start_download_data\n",
    "PATH_MOUNT = Path.cwd().parent / \"mount\"\n",
    "PATH_LOCAL_DATADIR = PATH_MOUNT / \"data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f6655ab-c3fe-4b16-b022-8fa321b5f9d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Task:\n",
    "    \n",
    "    def __init__(self, pair: str, timeframe: str, num_days: int):\n",
    "        self.pair = [pair]\n",
    "        self.timeframe = [timeframe]\n",
    "        self.num_days = num_days\n",
    "\n",
    "        \n",
    "class Downloader:\n",
    "    \n",
    "    def __init__(self, task_list: list, exchange: str, path_datadir: Path):\n",
    "        self.task_queue = deque(task_list)\n",
    "        self.print_queue = deque()\n",
    "        self.exchange = exchange\n",
    "        self.path_datadir = path_datadir / exchange\n",
    "        print(f\"Got {len(self.task_queue)} tasks.\")\n",
    "        print(f\"Datadir: {self.path_datadir}\")\n",
    "        \n",
    "    def start(self, num_threads: int):\n",
    "        print(\"Starting threads\")\n",
    "        threads = []\n",
    "        \n",
    "        for i in range(num_threads):\n",
    "            thread = Thread(target=self._download_job, args=(i,), daemon=True)\n",
    "            thread.start()\n",
    "            threads.append(thread)\n",
    "        \n",
    "        print_thread = Thread(target=self._print_job, daemon=True)\n",
    "        print_thread.start()\n",
    "        threads.append(print_thread)\n",
    "    \n",
    "        [it.join() for it in threads]\n",
    "    \n",
    "    def _download_job(self, thread_num: int):\n",
    "        time.sleep(thread_num * 3)\n",
    "        self._print(f\"Starting worker #{thread_num}\")\n",
    "        asyncio.set_event_loop(asyncio.new_event_loop())\n",
    "        \n",
    "        while len(self.task_queue) > 0:\n",
    "            try:\n",
    "                task = self.task_queue.pop()\n",
    "            except Exception as e:\n",
    "                self._print(f\"LOOP ERROR at Thread #{thread_num}: {e}.\")\n",
    "                continue\n",
    "            args = {\n",
    "                \"timeframes\": task.timeframe,\n",
    "                \"pairs\": task.pair,\n",
    "                \"exchange\": self.exchange,\n",
    "                \"days\": task.num_days,\n",
    "                \"datadir\": self.path_datadir,\n",
    "                \"verbosity\": logging.ERROR,\n",
    "            }\n",
    "            self._print(\n",
    "                f\"Thread #{thread_num} - Download {task.pair} {task.timeframe}. Tasks left: {len(self.task_queue)}\"\n",
    "            )\n",
    "            done = False\n",
    "            while not done:\n",
    "                # Fault Tolerance\n",
    "                try:\n",
    "                    start_download_data(args)\n",
    "                    done = True\n",
    "                except Exception as e:\n",
    "                    self._print(f\"DOWNLOAD ERROR at Thread #{thread_num}: {e}. ({task.pair} {task.timeframe})\")\n",
    "                    pass\n",
    "            \n",
    "            time.sleep(random.randint(1, 10))\n",
    "    \n",
    "    def _print(self, text: str):\n",
    "        self.print_queue.append(text)\n",
    "\n",
    "    def _print_job(self):\n",
    "        while len(self.task_queue) > 0:\n",
    "            while len(self.print_queue) > 0:\n",
    "                print(self.print_queue.pop())\n",
    "                \n",
    "    def _optimize_num_days(task: Task):\n",
    "        \"\"\"\n",
    "        Loads the JSON of the corresponding task. When the latest date was.\n",
    "        Then changes task.num_days starting from the latest date.\n",
    "        \"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67ae0bd5-0648-4617-9cf8-a58f1cf170a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "PAIRS_HIGH_CAP = [\n",
    "    \"BTC/USDT\",\"ETH/USDT\",\"ADA/USDT\",\"BNB/USDT\",\"XRP/USDT\",\"DOT/USDT\",\"DOGE/USDT\",\"ZEC/USDT\",\"NANO/USDT\",\"NEO/USDT\",\n",
    "    \"UNI/USDT\",\"BCH/USDT\",\"LINK/USDT\",\"LTC/USDT\",\"MATIC/USDT\",\"XLM/USDT\",\"SOL/USDT\",\"ETC/USDT\",\"VET/USDT\",\"THETA/USDT\",\n",
    "    \"EOS/USDT\",\"TRX/USDT\",\"FIL/USDT\",\"XMR/USDT\",\"AAVE/USDT\",\"MKR/USDT\",\"ATOM/USDT\",\"ALGO/USDT\",\"CAKE/USDT\",\"KSM/USDT\",\n",
    "    \"LUNA/USDT\",\"BTT/USDT\",\"AVAX/USDT\",\"COMP/USDT\",\"DASH/USDT\",\"DCR/USDT\",\"EGLD/USDT\",\"WAVES/USDT\",\"YFI/USDT\",\"XEM/USDT\",\n",
    "    \"CHZ/USDT\",\"SUSHI/USDT\",\"HOT/USDT\",\"ZIL/USDT\",\"SNX/USDT\",\"MANA/USDT\",\"ENJ/USDT\",\"HNT/USDT\",\"BAT/USDT\",\"NEAR/USDT\",\n",
    "    \"QTUM/USDT\",\"GRT/USDT\",\"ONE/USDT\",\"ONT/USDT\",\"BAKE/USDT\",\"BNT/USDT\",\"ZRX/USDT\",\"FTM/USDT\",\"OMG/USDT\",\"CELO/USDT\",\n",
    "    \"ICX/USDT\",\"ANKR/USDT\",\"RVN/USDT\",\"CRV/USDT\", \"FTT/USDT\", \"TFUEL/USDT\"\n",
    "]\n",
    "PAIRS_BLVT_DOWN = [\n",
    "    \"BTCDOWN/USDT\", \"BNBDOWN/USDT\", \"ETHDOWN/USDT\", \"AAVEDOWN/USDT\", \"XRPDOWN/USDT\", \"ADADOWN/USDT\", \"SUSHIDOWN/USDT\",\n",
    "    \"DOTDOWN/USDT\", \"1INCHDOWN/USDT\", \"LINKDOWN/USDT\", \"UNIDOWN/USDT\", \"SXPDOWN/USDT\", \"EOSDOWN/USDT\", \"BCHDOWN/USDT\",\n",
    "    \"YFIDOWN/USDT\", \"XLMDOWN/USDT\", \"FILDOWN/USDT\", \"TRXDOWN/USDT\", \"XTZDOWN/USDT\", \"LTCDOWN/USDT\",\n",
    "]\n",
    "pairs = PAIRS_HIGH_CAP + PAIRS_BLVT_DOWN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea163830-14ef-4229-a0cd-f64268eb9e40",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 1032 tasks.\n",
      "Datadir: C:\\CS\\Python\\crypto-collection\\freqtrade\\mount\\data\\binance\n",
      "Starting threads\n",
      "Thread #0 - Download ['LTCDOWN/USDT'] ['1d']. Tasks left: 1031\n",
      "Starting worker #0\n",
      "Starting worker #1\n",
      "Thread #1 - Download ['XTZDOWN/USDT'] ['1d']. Tasks left: 1030\n",
      "Starting worker #2\n",
      "Thread #2 - Download ['TRXDOWN/USDT'] ['1d']. Tasks left: 1029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\CS\\Python\\crypto-collection\\freqtrade\\superft\\freqtrade\\data\\history\\jsondatahandler.py:65: FutureWarning: casting datetime64[ns, UTC] values to int64 with .astype(...) is deprecated and will raise in a future version. Use .view(...) instead.\n",
      "  _data['date'] = _data['date'].astype(np.int64) // 1000 // 1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting worker #3\n",
      "Thread #3 - Download ['FILDOWN/USDT'] ['1d']. Tasks left: 1028\n",
      "Thread #0 - Download ['XLMDOWN/USDT'] ['1d']. Tasks left: 1027\n"
     ]
    }
   ],
   "source": [
    "# NOTE: Don't use 1 month (1M) timeframe as it will overwrite the 1 minute (1m) in Windows.\n",
    "timeframes = [\"1m\", \"3m\", \"5m\", \"15m\", \"30m\", \"1h\", \"2h\", \"4h\", \"6h\", \"8h\", \"12h\", \"1d\"]\n",
    "exchange = \"binance\"\n",
    "num_days = 30\n",
    "num_threads = 10\n",
    "\n",
    "tasks = []\n",
    "\n",
    "# Prepare the job\n",
    "for tf in timeframes:\n",
    "    for pair in pairs:\n",
    "        new_task = Task(pair, tf, num_days)\n",
    "        tasks.append(new_task)\n",
    "\n",
    "downloader = Downloader(tasks, exchange, PATH_LOCAL_DATADIR)\n",
    "downloader.start(num_threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feab938f-2a7e-4675-ae2b-18dea0d2d52a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.11.0 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.33<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">driven-glade-6</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/jliberooo/ft-datasets\" target=\"_blank\">https://wandb.ai/jliberooo/ft-datasets</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/jliberooo/ft-datasets/runs/1wimqowo\" target=\"_blank\">https://wandb.ai/jliberooo/ft-datasets/runs/1wimqowo</a><br/>\n",
       "                Run data is saved locally in <code>C:\\CS\\Python\\crypto-collection\\freqtrade\\superft\\wandb\\run-20210720_095838-1wimqowo</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 39604<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "718dcacd80d642369010b081e8facd74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 6557.66MB of 6557.66MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, maâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "BINANCE = PATH_LOCAL_DATADIR / \"binance\"\n",
    "datasets = {\n",
    "    \"binance_highcap\": BINANCE.glob(\"*.json\"),\n",
    "    \"binance_down\": BINANCE.glob(\"*DOWN*.json\"),\n",
    "}\n",
    "\n",
    "# Upload data to wandb\n",
    "DATASET_NAME = \"binance_highcap\"\n",
    "\n",
    "path_to_pairs = datasets[DATASET_NAME]\n",
    "\n",
    "with wandb.init(project=\"ft-datasets\") as run:\n",
    "    artifact = wandb.Artifact(DATASET_NAME, type=\"dataset\")\n",
    "    [artifact.add_file(it) for it in path_to_pairs]\n",
    "    run.log_artifact(artifact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f17d848-24c5-483b-bfcf-19a487460d09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
