{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Imports"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "%load_ext autoreload\r\n",
    "%autoreload 2\r\n",
    "\r\n",
    "from pathlib import Path\r\n",
    "from typing import List, Callable, Tuple, Any\r\n",
    "from wandb.wandb_run import Run\r\n",
    "from datetime import datetime, timedelta\r\n",
    "\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "from catboost import CatBoostClassifier, Pool, metrics, cv\r\n",
    "\r\n",
    "import attr\r\n",
    "import pandas as pd\r\n",
    "import gc\r\n",
    "import os\r\n",
    "import wandb\r\n",
    "import nest_asyncio\r\n",
    "import logging\r\n",
    "import sys\r\n",
    "import numpy as np\r\n",
    "\r\n",
    "nest_asyncio.apply()\r\n",
    "\r\n",
    "while \"freqtrade\" not in os.listdir():\r\n",
    "    os.chdir(\"..\")\r\n",
    "    if \"freqtrade\" in os.listdir():\r\n",
    "        nest_asyncio.apply()\r\n",
    "        logger = logging.getLogger(\"freqtrade.ml\")\r\n",
    "        handler = logging.StreamHandler(stream=sys.stdout)\r\n",
    "        handler.setFormatter(logging.Formatter(\"%(name)s - %(message)s\"))\r\n",
    "        logger.addHandler(handler)\r\n",
    "        logger.setLevel(logging.DEBUG)\r\n",
    "    \r\n",
    "from freqtrade.ml.lightning import LightningModule, LightningConfig\r\n",
    "from freqtrade.ml.trainer import TradingTrainer\r\n",
    "from freqtrade.ml.container import LightningContainer\r\n",
    "from freqtrade.ml import loader, lightning_utils\r\n",
    "\r\n",
    "from freqtrade.nbtools.helper import free_mem\r\n",
    "from freqtrade.nbtools.pairs import PAIRS_HIGHCAP_NONSTABLE\r\n",
    "\r\n",
    "container = None\r\n",
    "\r\n",
    "if container is not None:\r\n",
    "    print(\"Deleting container\")\r\n",
    "    free_mem(container)\r\n",
    "    \r\n",
    "gc.collect()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Lightning Module"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "MINI_DATA = False  # True if used for testing purposes\r\n",
    "\r\n",
    "attr.s(repr=False)\r\n",
    "class CatBoostModule(LightningModule):\r\n",
    "    \"\"\" Template for LightningModule \"\"\"\r\n",
    "        \r\n",
    "    def on_configure(self) -> LightningConfig:\r\n",
    "        \r\n",
    "        # This datetime can be replaced with datetime.now()\r\n",
    "        now = datetime(2021, 9, 1)\r\n",
    "\r\n",
    "        opt_start = datetime(2021, 3, 1)\r\n",
    "        opt_end = now - timedelta(days=60)\r\n",
    "        \r\n",
    "        # Lighting Configuration\r\n",
    "        config = LightningConfig(\r\n",
    "            \r\n",
    "            # Basic info\r\n",
    "            name        = \"15n30-catboost_l3\",\r\n",
    "            timeframe   = \"15m\",\r\n",
    "            exchange    = \"binance\",\r\n",
    "            \r\n",
    "            # Train and validation datetime\r\n",
    "            trainval_start  = datetime(2016, 1, 1),\r\n",
    "            trainval_end    = datetime(2021, 1, 1),\r\n",
    "            \r\n",
    "            # Backtest Optimization datetime\r\n",
    "            opt_start = opt_start,\r\n",
    "            opt_end   = opt_end,\r\n",
    "            \r\n",
    "            # Unbiased Backtest datetime\r\n",
    "            test_start = opt_end + timedelta(days=1),\r\n",
    "            test_end   = now,\r\n",
    "            \r\n",
    "            # Num training epochs\r\n",
    "            num_training_epochs = 12000,\r\n",
    "        )\r\n",
    "        \r\n",
    "        # Optional custom config attributes\r\n",
    "        config.add_custom(\"num_future_candles\", 2)\r\n",
    "        config.add_custom(\"num_classification_classes\", 5)\r\n",
    "        config.add_custom(\"hardware\", \"GPU\")\r\n",
    "        config.add_custom(\"learning_rate\", 0.005)\r\n",
    "        \r\n",
    "        return config\r\n",
    "        \r\n",
    "    def on_get_data_paths(self, cwd: Path, timeframe: str, exchange: str) -> List[Path]:\r\n",
    "        \"\"\" Where your data is stored\r\n",
    "        \"\"\"\r\n",
    "        path_data_exchange = cwd.parent / \"mount\" / \"data\" / exchange\r\n",
    "        maximum_data = 999 if not MINI_DATA else 5\r\n",
    "        \r\n",
    "        return [\r\n",
    "            datapath\r\n",
    "            for datapath in list(path_data_exchange.glob(f\"*-{timeframe}.json\"))\r\n",
    "            if datapath.name.split(\"-\")[0].replace(\"_\", \"/\")\r\n",
    "            in PAIRS_HIGHCAP_NONSTABLE[:maximum_data]\r\n",
    "        ]\r\n",
    "    \r\n",
    "    def on_add_features(self, df_onepair: pd.DataFrame) -> pd.DataFrame:\r\n",
    "        \"\"\" On Add Features will be used in inference\r\n",
    "        \"\"\"\r\n",
    "        # Start add features\r\n",
    "        spaces = [3, 5, 9, 15, 25, 50, 100, 200]\r\n",
    "        \r\n",
    "        for i in spaces:\r\n",
    "            df_onepair[f\"ml_smadiff_{i}\"] = (df_onepair['close'].rolling(i).mean() - df_onepair['close'])\r\n",
    "            df_onepair[f\"ml_maxdiff_{i}\"] = (df_onepair['close'].rolling(i).max() - df_onepair['close'])\r\n",
    "            df_onepair[f\"ml_mindiff_{i}\"] = (df_onepair['close'].rolling(i).min() - df_onepair['close'])\r\n",
    "            df_onepair[f\"ml_std_{i}\"] = df_onepair['close'].rolling(i).std()\r\n",
    "            df_onepair[f\"ml_ma_{i}\"] = df_onepair['close'].pct_change(i).rolling(i).mean()\r\n",
    "            # Volume\r\n",
    "            df_onepair[f\"ml_volmaxdiff_{i}\"] = (df_onepair['volume'].rolling(i).max() - df_onepair['volume'])\r\n",
    "            df_onepair[f\"ml_volmindiff_{i}\"] = (df_onepair['volume'].rolling(i).min() - df_onepair['volume'])\r\n",
    "            df_onepair[f\"ml_volsmadiff_{i}\"] = (df_onepair['volume'].rolling(i).mean() - df_onepair['volume'])\r\n",
    "            df_onepair[f\"ml_volstd_{i}\"] = df_onepair['volume'].rolling(i).std()\r\n",
    "            df_onepair[f\"ml_volma_{i}\"] = df_onepair['volume'].pct_change(i).rolling(i).mean()\r\n",
    "\r\n",
    "        previous_prices = 15\r\n",
    "        for i in range(previous_prices):\r\n",
    "            df_onepair[f\"ml_prevclose_{i}\"] = (df_onepair[\"close\"].shift(i) - df_onepair[\"close\"]) / df_onepair[\"close\"]\r\n",
    "            \r\n",
    "        df_onepair[\"ml_volume_pctchange\"] = df_onepair['volume'].pct_change()\r\n",
    "        df_onepair['ml_z_score_120'] = ((df_onepair[\"ml_ma_15\"] - df_onepair[\"ml_ma_15\"].rolling(21).mean() + 1e-9) \r\n",
    "                             / (df_onepair[\"ml_ma_15\"].rolling(21).std() + 1e-9))\r\n",
    "        \r\n",
    "        return df_onepair\r\n",
    "    \r\n",
    "    def on_add_labels(self, df_onepair: pd.DataFrame) -> pd.DataFrame:\r\n",
    "        \"\"\" Define the labels\r\n",
    "        \"\"\"\r\n",
    "        future_price = df_onepair['close'].shift(-self.config.num_future_candles)\r\n",
    "        ml_label = (future_price - df_onepair['close']) / df_onepair['close']\r\n",
    "        df_onepair[self.config.column_y] = pd.qcut(ml_label, self.config.num_classification_classes, labels=False)\r\n",
    "        return df_onepair\r\n",
    "    \r\n",
    "    def on_final_processing(self, df_allpairs: pd.DataFrame) -> Tuple[Any, Any, Any, Any]:\r\n",
    "        \"\"\" Define the data to X_train, X_val, y_train, y_val\r\n",
    "        \"\"\"\r\n",
    "        # val_split_date = pd.to_datetime(self.config.trainval_end - timedelta(days=60), utc=True, infer_datetime_format=True)\r\n",
    "        \r\n",
    "        # train = df_allpairs[df_allpairs[\"date\"] < val_split_date]\r\n",
    "        # val = df_allpairs[df_allpairs[\"date\"] >= val_split_date]\r\n",
    "\r\n",
    "        # X_train = train[self.config.columns_x]\r\n",
    "        # X_val = val[self.config.columns_x]\r\n",
    "        # y_train = train[self.config.column_y]\r\n",
    "        # y_val = val[self.config.column_y]\r\n",
    "\r\n",
    "        X = df_allpairs[self.config.columns_x]\r\n",
    "        y = df_allpairs[self.config.column_y]\r\n",
    "        X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=1)\r\n",
    "    \r\n",
    "        print(\"Num train datas:\", len(X_train))\r\n",
    "        print(\"Num val datas:\", len(X_val))\r\n",
    "\r\n",
    "        return X_train, X_val, y_train, y_val\r\n",
    "    \r\n",
    "    def on_define_model(self, run: Run, X_train, X_val, y_train, y_val) -> Any:\r\n",
    "        \"\"\" Define your model!\r\n",
    "        \"\"\"\r\n",
    "        return CatBoostClassifier(\r\n",
    "            custom_loss=[metrics.Accuracy()],\r\n",
    "            iterations=self.config.num_training_epochs, \r\n",
    "            task_type=self.config.hardware,\r\n",
    "            learning_rate=self.config.learning_rate,\r\n",
    "         )\r\n",
    "    \r\n",
    "    def on_start_training(self, run: Run, X_train, X_val, y_train, y_val):\r\n",
    "        \"\"\" Training / model fit code\r\n",
    "        \"\"\"\r\n",
    "        print(\"Start Training...\")\r\n",
    "        self.model: CatBoostClassifier\r\n",
    "        self.model.fit(\r\n",
    "            X_train, y_train,\r\n",
    "            eval_set=(X_val, y_val),\r\n",
    "            plot=True,\r\n",
    "            verbose=500,\r\n",
    "        )\r\n",
    "        print(\"Accuracy: %.2f\" % self.model.score(X_val, y_val))\r\n",
    "    \r\n",
    "    def on_predict(self, df_input_onepair: pd.DataFrame) -> pd.DataFrame:\r\n",
    "        \"\"\" Inference, used in freqtrade\r\n",
    "        \"\"\"\r\n",
    "        df_input_np = df_input_onepair.to_numpy()\r\n",
    "        preds = self.model.predict_proba(df_input_np)\r\n",
    "        df_preds = pd.DataFrame(preds)\r\n",
    "        return df_preds\r\n",
    "    \r\n",
    "    def on_training_step(self, run: Run, data: dict):\r\n",
    "        raise NotImplementedError()\r\n",
    "\r\n",
    "\r\n",
    "module = CatBoostModule()\r\n",
    "container = LightningContainer(module)\r\n",
    "tf = container.config.timeframe\r\n",
    "exchange = container.config.exchange\r\n",
    "paths = container.get_data_paths(Path.cwd(), tf, exchange)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "dataset = container.get_dataset()"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d22840b69d8b46c6a5959eb7b408cadb"
      },
      "text/plain": [
       "Load and preprocess data:   0%|          | 0/61 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Num train datas: 1745920\n",
      "Num val datas: 436480\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "# Vanilla load\r\n",
    "df_list = [\r\n",
    "    container._load_one(filepath)\r\n",
    "    for filepath in container.get_data_paths(Path.cwd(), container.module.config.timeframe, container.module.config.exchange)\r\n",
    "]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "from joblib import Parallel, delayed"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "# Joblib parallel load\r\n",
    "df_list = Parallel(n_jobs=8)(\r\n",
    "    delayed(container._load_one)(path) for path in tqdm(paths)\r\n",
    ")"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1dc4ef89808049888dfa890b7bdfa76e"
      },
      "text/plain": [
       "  0%|          | 0/61 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "from tqdm.notebook import tqdm"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5 64-bit ('freqtrade-futures': virtualenv)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  },
  "interpreter": {
   "hash": "01a71ee6dbb5cd792900cee3209e98c906676fa32abfeb4483902a4a80aaf85b"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}